A minimal linear regression implementation from scratch using NumPy to learn gradient descent concepts.

# Linear Regression From Scratch (Gradient Descent)

This project implements **linear regression from scratch using NumPy** â€” without using
any machine-learning libraries.

The goal was to understand:

- how gradient descent actually updates model weights  
- what â€œlossâ€ means and how we minimize it  
- why models can explode (become `inf` / `nan`) if the learning rate is too high  

This is one of my first ML fundamentals projects while preparing for
LLM / AI research roles.

---

## ğŸ§  Problem

We generate simple synthetic data:
y = 3x + 2 + noise

Our model tries to learn:

y_pred = w * x + b


We train it using **Mean Squared Error (MSE)** and manually coded gradients.

 Implementation

Key steps implemented:

1ï¸âƒ£ Create dataset  
2ï¸âƒ£ Initialize weights (`w`) and bias (`b`)  
3ï¸âƒ£ Compute predictions  
4ï¸âƒ£ Calculate loss  
5ï¸âƒ£ Compute gradients  
6ï¸âƒ£ Update weights with gradient descent  

Everything is done manually so the learning mechanics are visible.

 Learning Rate Lesson

At first the model **diverged**:



loss â†’ inf â†’ nan
weights â†’ nan


Reason: learning rate was too large.

After reducing it, training stabilized and the model learned values close to:



w â‰ˆ 3
b â‰ˆ 2


This same principle scales up to neural networks and LLMs.

---

 How to Run

### Install requirements

pip install numpy

Run the script
python linear_regression.py


You will see loss steadily decreasing and parameters converging.

ğŸ“Œ Output Example
step 0    | loss = 12.5
step 500  | loss â‰ˆ small
...
w â‰ˆ 3.0
b â‰ˆ 2.0

